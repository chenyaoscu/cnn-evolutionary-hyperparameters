{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-evolutionary-hyperparameters",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "huSsqJakOYoz",
        "colab_type": "code",
        "outputId": "aa122944-42fc-44d0-addc-158c60a85b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import keras\n",
        "import keras.layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "\n",
        "#Presets and things thatneed to be run first\n",
        "num_images = 10000\n",
        "num_generations = 25\n",
        "max_num_dense_nodes = 400\n",
        "random.seed(1000)\n",
        "set_random_seed(2)\n",
        "#Bad seeds: 0\n",
        "#Good seeds: \n",
        "\n",
        "#Import data and split into one large test set and multiple training and validation sets\n",
        "data = pd.read_csv('train.csv')\n",
        "images = data.iloc[:,1:]\n",
        "images = images / 255.0\n",
        "images = images.values.reshape(42000, 28, 28, 1)\n",
        "labels = data.iloc[:,:1].values.ravel()\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, train_size = 20000, random_state=1)\n",
        "\n",
        "train_data = []\n",
        "for i in range(10):\n",
        "    train_data.append(train_test_split(train_images, train_labels, train_size = 2000, random_state=i))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1zORRP5RlbVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#LayerMetadata and derived classesâ€”these classes wrap metadata so that information\n",
        "#about models can be moved around without returning an entire model\n",
        "class LayerMetadata:\n",
        "    def __init__(self, data_size):\n",
        "        self.data = np.zeros(data_size, dtype=\"int\")\n",
        "        \n",
        "    def to_string(self):\n",
        "        return \"badd oop\"\n",
        "\n",
        "class ConvLayerMetadata(LayerMetadata):\n",
        "    def __init__(self, kernels, pool_type, padding):\n",
        "        LayerMetadata.__init__(self, 3)\n",
        "        self.data[0] = max(1, kernels)\n",
        "        self.data[1] = pool_type #0 = MaxPooling, 1=AveragePooling\n",
        "        self.data[2] = padding #0 = valid, 1=same\n",
        "        \n",
        "    def to_string(self):\n",
        "        return \"Conv \" + str(self.data[0]) + \" \"\n",
        "        \n",
        "class DenseLayerMetadata(LayerMetadata):\n",
        "    def __init__(self, nodes):\n",
        "        LayerMetadata.__init__(self, 1)\n",
        "        self.data[0] = max(10, nodes)\n",
        "        \n",
        "    def to_string(self):\n",
        "        return \"Dense \" + str(self.data[0]) + \" \"\n",
        "\n",
        "#A class containing a list of LayerMetadata and its evolvedness\n",
        "class ModelMetadata:\n",
        "    def __init__(self, layers, evolvedness, accuracy, data_number):\n",
        "        self.layers = layers\n",
        "        self.evolvedness = evolvedness\n",
        "        self.accuracy = accuracy\n",
        "        self.data_number = data_number\n",
        "        \n",
        "    def to_string(self):\n",
        "        str = \"\"\n",
        "        for layer in self.layers:\n",
        "            str += layer.to_string()\n",
        "        e = repr(self.evolvedness)\n",
        "        a = repr(self.accuracy)\n",
        "        str += \" Evolvedness: \" + e + \" Accuracy:\" + a\n",
        "        return str\n",
        "\n",
        "#A class comprising a Keras model and metadata about it, along with static\n",
        "#methods useful for building new ModelWithMetadatas\n",
        "#When constructed with no arguments, a random model is generated, otherwise the\n",
        "#model is constructed from the input metadata\n",
        "class ModelWithMetadata:\n",
        "    def __init__(self, metadata):\n",
        "        if metadata == None:\n",
        "            self.metadata = self.get_random_metadata()\n",
        "            self.model = self.get_from_metadata(self.metadata)\n",
        "        else:\n",
        "            self.model = self.get_from_metadata(metadata)\n",
        "            self.metadata = metadata\n",
        "        self.metadata.accuracy = self.get_accuracy()\n",
        "        \n",
        "    #Gets the accuracy of a model\n",
        "    def get_accuracy(self):\n",
        "        ada = tf.train.AdamOptimizer()\n",
        "        try:\n",
        "            self.model.compile(optimizer=ada, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            x = self.metadata.data_number\n",
        "            self.model.fit(train_data[x][0], train_data[x][2], batch_size=500, epochs=20, verbose=0,)\n",
        "            return self.model.evaluate(train_data[x][1], train_data[x][3], verbose=0)[1]\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"Model failed\")\n",
        "            return 0.0\n",
        "    \n",
        "    #Returns a model determined by input metadata\n",
        "    @staticmethod\n",
        "    def get_from_metadata(metadata):\n",
        "        model = keras.Sequential()\n",
        "        try: \n",
        "            added_dense_layer = False\n",
        "            added_first_layer = False\n",
        "            for layer in metadata.layers:\n",
        "                if type(layer) is ConvLayerMetadata:\n",
        "                    if not added_first_layer:  \n",
        "                        model.add(keras.layers.Conv2D(layer.data[0], 2, strides=(1,1),input_shape=(28, 28, 1),activation=\"relu\", padding= \"valid\" if layer.data[2] == 0 else \"same\"))\n",
        "                        added_first_layer = True\n",
        "                    else:\n",
        "                        model.add(keras.layers.Conv2D(layer.data[0], 2, strides=(1,1),activation=\"relu\",padding = \"valid\"))\n",
        "                    if layer.data[1] == 0:\n",
        "                         model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding= \"valid\" if layer.data[2] == 0 else \"same\"))\n",
        "                    else:\n",
        "                         model.add(keras.layers.AveragePooling2D(pool_size=2, strides=None, padding= \"same\" if layer.data[2] == 1 else \"valid\"))\n",
        "                if type(layer) is DenseLayerMetadata:\n",
        "                    if not added_dense_layer:\n",
        "                        model.add(keras.layers.Flatten())\n",
        "                        added_dense_layer = True\n",
        "                    model.add(keras.layers.Dense(layer.data[0], activation=\"relu\", use_bias=True, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
        "            model.add(keras.layers.Dense(10, activation=\"softmax\", use_bias=True, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            #This shouldn't happen and is a bug. However, it doesn't impact\n",
        "            #program performance in a non-negligible way, so it represents a\n",
        "            #longterm TODO\n",
        "            \n",
        "    \n",
        "    #Returns a ModelMetadata determined randomly\n",
        "    @staticmethod\n",
        "    def get_random_metadata():\n",
        "        layers = []\n",
        "        #for i in range(random.randint(1,3)):\n",
        "            #kernels = random.randint(1, 150)\n",
        "            #pool_type = random.randint(0,1)\n",
        "            #padding = random.randint(0,1)\n",
        "            #layers.append(ConvLayerMetadata(kernels, pool_type, padding))\n",
        "        for i in range(random.randint(3,6)):\n",
        "            layers.append(DenseLayerMetadata(random.randint(500,3000)))\n",
        "        return ModelMetadata(layers, 0, 0, random.randint(0, 9))\n",
        "\n",
        "    #Returns a ModelMetadata object representing a small mutation of its parents'\n",
        "    #input metadata m\n",
        "    #heaviness - allows manipulation of the extent of possible mutation. Values\n",
        "    #of 1 to 3 are good?\n",
        "    @staticmethod\n",
        "    def mutate(input_m, heaviness):\n",
        "        m = copy.deepcopy(input_m)\n",
        "        index = random.randint(0, len(m.layers) - 1)\n",
        "        for i in range(10 + heaviness):               \n",
        "            if type(m.layers[index]) is ConvLayerMetadata:\n",
        "                x = random.randint(0,2)\n",
        "                if x == 0:\n",
        "                    m.layers[index].data[0] = max(1, m.layers[index].data[0] + random.randint(-2, 3))\n",
        "                if x == 1:\n",
        "                    m.layers[index].data[1] = max(1, m.layers[index].data[1] + random.randint(-1, 1))\n",
        "                if x == 2:\n",
        "                    m.layers[index].data[2] = max(1, m.layers[index].data[2] + random.randint(-1, 1))\n",
        "            if type(m.layers[index]) is DenseLayerMetadata:\n",
        "                m.layers[index].data[0] = max(10, + m.layers[index].data[0] + random.randint(-5, 5))\n",
        "        m.evolvedness += 1\n",
        "        return m\n",
        "    \n",
        "    #Returns a metadata object formed by breeding the metadata elements of m_list\n",
        "    #Because m_list can have a variable length, it's possible for an entire\n",
        "    #population to contribute to one model's DNA\n",
        "    @staticmethod\n",
        "    def breed(m_list):\n",
        "        m_list.sort(key=lambda metadata: len(metadata.layers))\n",
        "        dense_chosen = False                      \n",
        "        num_layers = random.randint(len(m_list[0].layers), len(m_list[-1].layers))\n",
        "        layers = []\n",
        "        for i in range(num_layers):\n",
        "            while True:\n",
        "                index = random.randint(0, len(m_list) - 1)\n",
        "                if i < len(m_list[index].layers):\n",
        "                    if type(m_list[index].layers[i]) is DenseLayerMetadata:\n",
        "                        dense_chosen = True\n",
        "                    if not (dense_chosen and type(m_list[index].layers[i]) is ConvLayerMetadata):\n",
        "                        layers.append(m_list[index].layers[i])\n",
        "                        break;\n",
        "        evolvedness = 0\n",
        "        for m in m_list:\n",
        "            evolvedness += m.evolvedness\n",
        "        evolvedness = evolvedness / len(m_list) + 1\n",
        "        m = ModelMetadata(layers, evolvedness, 0, random.randint(0, 31))\n",
        "        return m\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EjoYPXYQBb3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "global best_accuracies\n",
        "best_accuracies = np.zeros(num_generations)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "#Returns the accuracy of the models, as an ensemble with weighted voting\n",
        "def get_ensemble_accuracy(model_metadata):\n",
        "    models = []\n",
        "    for m in model_metadata:\n",
        "        models.append(ModelWithMetadata(m))\n",
        "    if len(models) == 0:\n",
        "        print(\"The models went extinct\")\n",
        "        return 0.0\n",
        "    models.sort(reverse=True, key=lambda model: model.metadata.accuracy) #Best model in smallest index\n",
        "    results = np.array([model.model.predict_proba(test_images) for model in models])\n",
        "    predictions_temp = np.zeros(shape=(len(test_images), 10))\n",
        "    for i in range(results.shape[0]):\n",
        "        for j in range(results.shape[1]):\n",
        "            x = np.argmax(results[i][j])\n",
        "            predictions_temp[j][x] += models[i].metadata.accuracy - models[-1].metadata.accuracy\n",
        "    predictions = np.array([np.argmax(arr) for arr in predictions_temp])\n",
        "    return accuracy_score(test_labels, predictions)\n",
        "\n",
        "#Returns if the best accuracy hasn't increased recently enough, if so, it's\n",
        "#experience shows that it's unlikely that it will soon\n",
        "def evaluate_progress(generation):\n",
        "    to_return = (False, False)\n",
        "    try:\n",
        "        if best_accuracies[generation] <= best_accuracies[generation-2]:\n",
        "            to_return[0] = True\n",
        "    except:\n",
        "        pass\n",
        "    try:\n",
        "        if best_accuracies[generation] <= best_accuracies[generation-3]:\n",
        "            to_return[1] = True\n",
        "    except:\n",
        "        pass\n",
        "    return to_return\n",
        "        \n",
        "\n",
        "#Returns the average accuracy of a group of models\n",
        "def get_generation_stats(model_metadata, generation):\n",
        "    generation_accuracy = 0\n",
        "    for m in model_metadata:\n",
        "        generation_accuracy += m.accuracy\n",
        "    best_accuracies[generation] = model_metadata[0].accuracy\n",
        "    x = evaluate_progress(generation)\n",
        "    return x[0], x[1], generation_accuracy / len(model_metadata)\n",
        "\n",
        "#Assumes there are accuracies\n",
        "def evolve(num_generations):\n",
        "    counter = 0\n",
        "    need_new_genes = False #Keeps track of a rough indicator of if there's too little diversity\n",
        "    model_metadata = []\n",
        "    best_metadata = []\n",
        "    #Construct generation zero\n",
        "    counter = 0\n",
        "    while len(model_metadata) < 20:\n",
        "        m = ModelWithMetadata(None)\n",
        "        model_metadata.append(m.metadata)\n",
        "        print(counter, \"Added\", m.metadata.to_string(), len(model_metadata))\n",
        "        counter += 1\n",
        "        del m\n",
        "    print(\"Got initial models\")\n",
        "    for i in range(num_generations):\n",
        "        counter = 0\n",
        "        #Best model in smallest index\n",
        "        model_metadata.sort(reverse=True, key=lambda metadata: metadata.accuracy) \n",
        "        #Get the accuracy of the generation\n",
        "        results = get_generation_stats(model_metadata, i)\n",
        "        print(\"GENERATION:\", i, \"Best accuracy:\", model_metadata[0].accuracy, \"Average accuracy:\", results[2], \"New genes needed:\", results[0])\n",
        "        print(model_metadata[0].to_string())\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        #Add asexual models\n",
        "        for i in range(min(2, len(model_metadata))):\n",
        "            m = ModelWithMetadata(ModelWithMetadata.mutate(model_metadata[i], 1))\n",
        "            model_metadata.append(m.metadata)\n",
        "            print(counter, \"Added\", m.metadata.to_string())\n",
        "            counter += 1\n",
        "            del m\n",
        "            m = ModelWithMetadata(ModelWithMetadata.mutate(model_metadata[i], 1))\n",
        "            model_metadata.append(m.metadata)\n",
        "            print(counter, \"Added\", m.metadata.to_string())\n",
        "            counter += 1\n",
        "            del m\n",
        "                                  \n",
        "        #Allow only good models to breed\n",
        "        model_metadata.sort(reverse=True, key=lambda m: m.accuracy)\n",
        "        \n",
        "        done = False\n",
        "        for m in model_metadata:\n",
        "            if m.accuracy > .96:\n",
        "                best_metadata.append(m)\n",
        "                done = True\n",
        "        if done:\n",
        "            print(\"Ending generation early\")\n",
        "            break\n",
        "\n",
        "        \n",
        "        del model_metadata[10 - i:]\n",
        "                \n",
        "        #Add sexual models from best 3\n",
        "        #for j in range(8):\n",
        "            #rand_1 = random.randint(0, min(3, len(model_metadata) - 1))\n",
        "            #rand_2 = random.randint(0, min(3, len(model_metadata) - 1))\n",
        "            #rand_3 = random.randint(0, len(model_metadata) - 1)\n",
        "            #rand_4 = random.randint(0, len(model_metadata) - 1)\n",
        "            #models_to_breed = []\n",
        "            #models_to_breed.append(model_metadata[rand_1])\n",
        "            #models_to_breed.append(model_metadata[rand_2])\n",
        "            #models_to_breed.append(model_metadata[rand_3])\n",
        "            #models_to_breed.append(model_metadata[rand_4])\n",
        "            #m = ModelWithMetadata(ModelWithMetadata.breed(models_to_breed))\n",
        "            #model_metadata.append(m.metadata)\n",
        "           # print(counter, \"Added\", m.metadata.to_string())\n",
        "            #counter += 1\n",
        "            #del m\n",
        "\n",
        "    return best_metadata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsnNpVa6QGis",
        "colab_type": "code",
        "outputId": "5982b070-4e48-444e-e0f1-513a6b691103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2040
        }
      },
      "cell_type": "code",
      "source": [
        "#Returns the top three models from several bloodlines from which intermingling is\n",
        "#forbidden to be used in a voting algorithm. This is to hopefully maximize the variance\n",
        "#in the most accurate votes\n",
        "#Inputs: num_generations per bloodline, num_bloodlines\n",
        "def get_evolution_results(num_generations=8, bloodlines=8):\n",
        "    best_models = []\n",
        "    for i in range(bloodlines):\n",
        "        returned_models = sorted(evolve(num_generations), reverse=True, key=lambda model: model.accuracy)\n",
        "        del returned_models[3:]\n",
        "        for model in returned_models:\n",
        "            best_models.append(model)\n",
        "    print(\"Final ensemble accuracy: \", get_accuracy(best_models))\n",
        "    \n",
        "get_evolution_results(5,8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Added Dense 906 Dense 2112 Dense 1945 Dense 757 Dense 2416 Dense 1178  Evolvedness: 0 Accuracy:0.9243888888888889 1\n",
            "1 Added Dense 1033 Dense 1408 Dense 1485 Dense 1991 Dense 2502 Dense 1331  Evolvedness: 0 Accuracy:0.8888333333333334 2\n",
            "2 Added Dense 2376 Dense 1249 Dense 666 Dense 2496  Evolvedness: 0 Accuracy:0.9264444444444444 3\n",
            "3 Added Dense 2202 Dense 1323 Dense 595 Dense 2694 Dense 2418 Dense 1393  Evolvedness: 0 Accuracy:0.9243333333333333 4\n",
            "4 Added Dense 945 Dense 1532 Dense 1156 Dense 1671  Evolvedness: 0 Accuracy:0.9293888888888889 5\n",
            "5 Added Dense 1786 Dense 567 Dense 1551  Evolvedness: 0 Accuracy:0.924 6\n",
            "6 Added Dense 1295 Dense 1696 Dense 2061  Evolvedness: 0 Accuracy:0.9265 7\n",
            "7 Added Dense 1448 Dense 1963 Dense 2489 Dense 990  Evolvedness: 0 Accuracy:0.9255555555555556 8\n",
            "8 Added Dense 2376 Dense 2000 Dense 2486 Dense 2941 Dense 1648 Dense 2429  Evolvedness: 0 Accuracy:0.9042222222222223 9\n",
            "9 Added Dense 723 Dense 1085 Dense 2342  Evolvedness: 0 Accuracy:0.9264444444444444 10\n",
            "10 Added Dense 1696 Dense 603 Dense 2017 Dense 1017  Evolvedness: 0 Accuracy:0.9237222222222222 11\n",
            "11 Added Dense 2562 Dense 1855 Dense 1922 Dense 1880  Evolvedness: 0 Accuracy:0.9258333333333333 12\n",
            "12 Added Dense 1325 Dense 2134 Dense 801 Dense 1422 Dense 1490 Dense 1734  Evolvedness: 0 Accuracy:0.9185555555555556 13\n",
            "13 Added Dense 1825 Dense 525 Dense 2799 Dense 2920 Dense 1178 Dense 905  Evolvedness: 0 Accuracy:0.9091111111111111 14\n",
            "14 Added Dense 2417 Dense 2038 Dense 2124 Dense 2626 Dense 600 Dense 1721  Evolvedness: 0 Accuracy:0.9058333333333334 15\n",
            "15 Added Dense 1326 Dense 1323 Dense 923  Evolvedness: 0 Accuracy:0.9266111111111112 16\n",
            "16 Added Dense 1076 Dense 903 Dense 804 Dense 1045  Evolvedness: 0 Accuracy:0.9290555555555555 17\n",
            "17 Added Dense 1357 Dense 2781 Dense 1895 Dense 919 Dense 1361  Evolvedness: 0 Accuracy:0.9269444444444445 18\n",
            "18 Added Dense 1134 Dense 1999 Dense 2921 Dense 1190  Evolvedness: 0 Accuracy:0.9286666666666666 19\n",
            "19 Added Dense 1644 Dense 1420 Dense 1385 Dense 1611 Dense 566 Dense 581  Evolvedness: 0 Accuracy:0.9230555555555555 20\n",
            "Got initial models\n",
            "GENERATION: 0 Best accuracy: 0.9293888888888889 Average accuracy: 0.920875 New genes needed: False\n",
            "Dense 945 Dense 1532 Dense 1156 Dense 1671  Evolvedness: 0 Accuracy:0.9293888888888889\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 945 Dense 1539 Dense 1156 Dense 1671  Evolvedness: 1 Accuracy:0.9262777777777778\n",
            "1 Added Dense 947 Dense 1532 Dense 1156 Dense 1671  Evolvedness: 1 Accuracy:0.9281111111111111\n",
            "2 Added Dense 1076 Dense 903 Dense 804 Dense 1035  Evolvedness: 1 Accuracy:0.9257222222222222\n",
            "3 Added Dense 1076 Dense 908 Dense 804 Dense 1045  Evolvedness: 1 Accuracy:0.9290555555555555\n",
            "GENERATION: 1 Best accuracy: 0.9293888888888889 Average accuracy: 0.9278641975308641 New genes needed: False\n",
            "Dense 945 Dense 1532 Dense 1156 Dense 1671  Evolvedness: 0 Accuracy:0.9293888888888889\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 945 Dense 1530 Dense 1156 Dense 1671  Evolvedness: 1 Accuracy:0.9293333333333333\n",
            "1 Added Dense 945 Dense 1533 Dense 1156 Dense 1671  Evolvedness: 1 Accuracy:0.9302777777777778\n",
            "2 Added Dense 1076 Dense 903 Dense 804 Dense 1036  Evolvedness: 1 Accuracy:0.9307222222222222\n",
            "3 Added Dense 1076 Dense 903 Dense 804 Dense 1046  Evolvedness: 1 Accuracy:0.9310555555555555\n",
            "GENERATION: 2 Best accuracy: 0.9310555555555555 Average accuracy: 0.9295185185185184 New genes needed: False\n",
            "Dense 1076 Dense 903 Dense 804 Dense 1046  Evolvedness: 1 Accuracy:0.9310555555555555\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 1093 Dense 903 Dense 804 Dense 1046  Evolvedness: 2 Accuracy:0.9271111111111111\n",
            "1 Added Dense 1076 Dense 903 Dense 804 Dense 1046  Evolvedness: 2 Accuracy:0.9273888888888889\n",
            "2 Added Dense 1065 Dense 903 Dense 804 Dense 1036  Evolvedness: 2 Accuracy:0.9268333333333333\n",
            "3 Added Dense 1076 Dense 903 Dense 810 Dense 1036  Evolvedness: 2 Accuracy:0.9265\n",
            "GENERATION: 3 Best accuracy: 0.9310555555555555 Average accuracy: 0.9295185185185184 New genes needed: False\n",
            "Dense 1076 Dense 903 Dense 804 Dense 1046  Evolvedness: 1 Accuracy:0.9310555555555555\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 1071 Dense 903 Dense 804 Dense 1046  Evolvedness: 2 Accuracy:0.9286111111111112\n",
            "1 Added Dense 1076 Dense 903 Dense 799 Dense 1046  Evolvedness: 2 Accuracy:0.9284444444444444\n",
            "2 Added Dense 1076 Dense 903 Dense 804 Dense 1037  Evolvedness: 2 Accuracy:0.9299444444444445\n",
            "3 Added Dense 1078 Dense 903 Dense 804 Dense 1036  Evolvedness: 2 Accuracy:0.9274444444444444\n",
            "GENERATION: 4 Best accuracy: 0.9310555555555555 Average accuracy: 0.9297222222222222 New genes needed: False\n",
            "Dense 1076 Dense 903 Dense 804 Dense 1046  Evolvedness: 1 Accuracy:0.9310555555555555\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 1076 Dense 912 Dense 804 Dense 1046  Evolvedness: 2 Accuracy:0.9272222222222222\n",
            "1 Added Dense 1094 Dense 903 Dense 804 Dense 1046  Evolvedness: 2 Accuracy:0.9271111111111111\n",
            "2 Added Dense 1076 Dense 899 Dense 804 Dense 1036  Evolvedness: 2 Accuracy:0.9273333333333333\n",
            "3 Added Dense 1076 Dense 922 Dense 804 Dense 1036  Evolvedness: 2 Accuracy:0.9267777777777778\n",
            "0 Added Dense 1245 Dense 1185 Dense 1411 Dense 1693 Dense 1236  Evolvedness: 0 Accuracy:0.9261666666666667 1\n",
            "1 Added Dense 2272 Dense 1423 Dense 2792 Dense 1407  Evolvedness: 0 Accuracy:0.9253333333333333 2\n",
            "2 Added Dense 1966 Dense 1597 Dense 2921 Dense 1332 Dense 2041  Evolvedness: 0 Accuracy:0.9309444444444445 3\n",
            "3 Added Dense 2019 Dense 1093 Dense 2865 Dense 1827 Dense 2007  Evolvedness: 0 Accuracy:0.9183333333333333 4\n",
            "4 Added Dense 2653 Dense 1764 Dense 2913 Dense 1216  Evolvedness: 0 Accuracy:0.9265555555555556 5\n",
            "5 Added Dense 2180 Dense 1765 Dense 2603 Dense 940 Dense 2999  Evolvedness: 0 Accuracy:0.9317777777777778 6\n",
            "6 Added Dense 1299 Dense 2847 Dense 1903 Dense 1433 Dense 2529  Evolvedness: 0 Accuracy:0.9135555555555556 7\n",
            "7 Added Dense 2601 Dense 2863 Dense 1863 Dense 1289 Dense 1704 Dense 2779  Evolvedness: 0 Accuracy:0.9235555555555556 8\n",
            "8 Added Dense 1296 Dense 1721 Dense 1312 Dense 891  Evolvedness: 0 Accuracy:0.9246111111111112 9\n",
            "9 Added Dense 1278 Dense 1123 Dense 2741  Evolvedness: 0 Accuracy:0.9307777777777778 10\n",
            "10 Added Dense 1726 Dense 588 Dense 659 Dense 2237 Dense 2387 Dense 2692  Evolvedness: 0 Accuracy:0.9263888888888889 11\n",
            "11 Added Dense 1387 Dense 687 Dense 2240 Dense 1176  Evolvedness: 0 Accuracy:0.9282777777777778 12\n",
            "12 Added Dense 949 Dense 2410 Dense 1415 Dense 2241 Dense 2558 Dense 1922  Evolvedness: 0 Accuracy:0.9227222222222222 13\n",
            "13 Added Dense 1860 Dense 2757 Dense 1884 Dense 667  Evolvedness: 0 Accuracy:0.9306666666666666 14\n",
            "14 Added Dense 2597 Dense 518 Dense 2099 Dense 1864 Dense 2514 Dense 1707  Evolvedness: 0 Accuracy:0.9184444444444444 15\n",
            "15 Added Dense 2349 Dense 1313 Dense 1265 Dense 707  Evolvedness: 0 Accuracy:0.9248333333333333 16\n",
            "16 Added Dense 883 Dense 2505 Dense 1189 Dense 743  Evolvedness: 0 Accuracy:0.9224444444444444 17\n",
            "17 Added Dense 1285 Dense 2144 Dense 1654 Dense 1617 Dense 1217 Dense 1192  Evolvedness: 0 Accuracy:0.9195 18\n",
            "18 Added Dense 791 Dense 1427 Dense 1036 Dense 2159  Evolvedness: 0 Accuracy:0.9304444444444444 19\n",
            "19 Added Dense 1770 Dense 1039 Dense 1503 Dense 2812 Dense 1600  Evolvedness: 0 Accuracy:0.9248888888888889 20\n",
            "Got initial models\n",
            "GENERATION: 0 Best accuracy: 0.9317777777777778 Average accuracy: 0.925011111111111 New genes needed: False\n",
            "Dense 2180 Dense 1765 Dense 2603 Dense 940 Dense 2999  Evolvedness: 0 Accuracy:0.9317777777777778\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 2180 Dense 1765 Dense 2603 Dense 956 Dense 2999  Evolvedness: 1 Accuracy:0.9272222222222222\n",
            "1 Added Dense 2180 Dense 1765 Dense 2603 Dense 909 Dense 2999  Evolvedness: 1 Accuracy:0.9324444444444444\n",
            "2 Added Dense 1966 Dense 1597 Dense 2914 Dense 1332 Dense 2041  Evolvedness: 1 Accuracy:0.9293333333333333\n",
            "3 Added Dense 1966 Dense 1597 Dense 2921 Dense 1333 Dense 2041  Evolvedness: 1 Accuracy:0.9299444444444445\n",
            "GENERATION: 1 Best accuracy: 0.9324444444444444 Average accuracy: 0.9305123456790123 New genes needed: False\n",
            "Dense 2180 Dense 1765 Dense 2603 Dense 909 Dense 2999  Evolvedness: 1 Accuracy:0.9324444444444444\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 2180 Dense 1765 Dense 2599 Dense 909 Dense 2999  Evolvedness: 2 Accuracy:0.9309444444444445\n",
            "1 Added Dense 2180 Dense 1748 Dense 2603 Dense 909 Dense 2999  Evolvedness: 2 Accuracy:0.9238888888888889\n",
            "2 Added Dense 2180 Dense 1765 Dense 2603 Dense 943 Dense 2999  Evolvedness: 1 Accuracy:0.8731666666666666\n",
            "3 Added Dense 2180 Dense 1765 Dense 2601 Dense 940 Dense 2999  Evolvedness: 1 Accuracy:0.9301111111111111\n",
            "GENERATION: 2 Best accuracy: 0.9324444444444444 Average accuracy: 0.930895061728395 New genes needed: False\n",
            "Dense 2180 Dense 1765 Dense 2603 Dense 909 Dense 2999  Evolvedness: 1 Accuracy:0.9324444444444444\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0 Added Dense 2180 Dense 1765 Dense 2603 Dense 908 Dense 2999  Evolvedness: 2 Accuracy:0.9278333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}