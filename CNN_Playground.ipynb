{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Playground.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tristanengst/cnn-evolutionary-hyperparameters/blob/master/CNN_Playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Usb9dxh5GJQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eb933ffc-f9a9-4096-ab02-0e79547c908a"
      },
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "#Presets\n",
        "num_images = 2000\n",
        "\n",
        "#Import dataâ€”data is local\n",
        "data = pd.read_csv('train.csv')\n",
        "images = data.iloc[0:num_images,1:]\n",
        "train_images = images / 255.0\n",
        "train_images = train_images.values.reshape(num_images, 28, 28, 1)\n",
        "train_labels = data.iloc[0:num_images,:1]\n",
        "\n",
        "train_images, validation_images, train_labels, validation_labels = train_test_split(train_images, train_labels, train_size = .5, random_state=42)\n",
        "\n",
        "models = []\n",
        "\n",
        "class Metadata:\n",
        "    def __init__(self, dense_layers, dense_layer_nodes, kernels_0, kernels_1):\n",
        "        self.dense_layers = dense_layers\n",
        "        self.dense_layer_nodes = dense_layer_nodes\n",
        "        self.kernels_0 = kernels_0\n",
        "        self.kernels_1 = kernels_1\n",
        "\n",
        "class ModelWithMetadata:\n",
        "    def get_accuracy(self, model):\n",
        "        try:\n",
        "            model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            model.fit(train_images, train_labels, batch_size=100, epochs=10, verbose=0, validation_data=(validation_images, validation_labels))\n",
        "            return model.evaluate(validation_images, validation_labels)[1]\n",
        "        except:\n",
        "            print(\"Model failed\")\n",
        "            return 0.0\n",
        "    \n",
        "    def __init__(self, metadata):\n",
        "        self.model = self.get_model_from_seed(metadata)\n",
        "        self.metadata = metadata\n",
        "        self.accuracy = self.get_accuracy(self.model)\n",
        "        print(\"Trained model with accuracy \", self.accuracy)\n",
        "    \n",
        "    #Returns a model, input is of type metadata\n",
        "    def get_model_from_seed(self, metadata):\n",
        "        model = keras.Sequential()\n",
        "        model.add(keras.layers.Conv2D(metadata.kernels_0, 2, strides=(1,1), padding=\"valid\", input_shape=(28, 28, 1), activation=\"relu\"))\n",
        "        model.add(keras.layers.AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid',))\n",
        "        model.add(keras.layers.Conv2D(metadata.kernels_1, 2, strides=(1,1), padding=\"valid\", input_shape=(28, 28, 1), activation=\"relu\"))\n",
        "        model.add(keras.layers.AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid',))\n",
        "        model.add(keras.layers.Flatten())\n",
        "        for i in range(metadata.dense_layers):\n",
        "            model.add(keras.layers.Dense(metadata.dense_layer_nodes[i], activation=\"relu\", use_bias=True, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
        "        model.add(keras.layers.Dense(10, activation=\"softmax\", use_bias=True, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
        "        return model\n",
        "\n",
        "def mutate(model):\n",
        "    dense_layers = max(1, model.metadata.dense_layers + random.randint(-1,2))\n",
        "    dense_layer_nodes = list()\n",
        "    for i in range(dense_layers):\n",
        "        if (i < len(model.metadata.dense_layer_nodes)):\n",
        "                dense_layer_nodes.append(max(10, model.metadata.dense_layer_nodes[i] + random.randint(-20,20)))\n",
        "        else:\n",
        "                dense_layer_nodes.append(random.randint(10,1001))\n",
        "    kernels_0 = max(10, model.metadata.kernels_0 + random.randint(-20, 20))\n",
        "    kernels_1 = max(10, model.metadata.kernels_1 + random.randint(-20, 20))\n",
        "    return(Metadata(dense_layers, dense_layer_nodes, kernels_0, kernels_1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "V0CJgRPNx1ak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3fef6acd-5bcd-41fb-a3e9-5327e93e385c"
      },
      "cell_type": "code",
      "source": [
        "def evolve(num_generations):\n",
        "    for i in range(num_generations):\n",
        "        generation_accuracy = 0\n",
        "        for i in range(10):\n",
        "            models.append(ModelWithMetadata(mutate(models[0]))) #Find best model and delete the rest\n",
        "            generation_accuracy = generation_accuracy + models[i].accuracy\n",
        "        models.sort(key=lambda model: model.accuracy)\n",
        "        while (len(models) > 1):\n",
        "            models.pop(0)\n",
        "        print(\"Best accuracy of generation was\", models[0].accuracy, \"Average generational accuracy:\", generation_accuracy / 10)\n",
        "    print(models[0].model.summary())\n",
        "    print(models[0].metadata)\n",
        "    return models[0].model.get_config()\n",
        "\n",
        "models.append(ModelWithMetadata(Metadata(3, [1000, 1000, 200], 128, 32)))\n",
        "evolve(10)\n",
        "        \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 1s 733us/step\n",
            "Trained model with accuracy  0.937\n",
            "1000/1000 [==============================] - 1s 811us/step\n",
            "Trained model with accuracy  0.921\n",
            "1000/1000 [==============================] - 1s 692us/step\n",
            "Trained model with accuracy  0.933\n",
            "1000/1000 [==============================] - 1s 660us/step\n",
            "Trained model with accuracy  0.926\n",
            "1000/1000 [==============================] - 1s 813us/step\n",
            "Trained model with accuracy  0.926\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}